---
title: "PDA_EDA"
author: "Maria Pia El Asmar & Hasini Gunawardena"
date: "10/30/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Packages to be put in the next section at the end of the project
```{r setup, echo = FALSE, warning = FALSE, message = FALSE}
library(tidyverse)
library(DT)
library(Hmisc)  
library(tidyquant)
library(ggthemes)
library(RColorBrewer)
library(corrplot)
library(psych)
library(GGally)
library(corrr)
library(corrplot)
library(ggcorrplot)
library(kableExtra)
#library(DataExplorer)
library(inspectdf)
library(explore)
```


```{r setup2, echo = FALSE, warning = FALSE, message = FALSE}
knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
  cache = TRUE,
  fig.retina = 0.8, # figures are either vectors or 300 dpi diagrams
  dpi = 300,
  out.width = "70%",
  fig.align = 'center',
  fig.width = 6,
  fig.asp = 0.618,  
  fig.show = "hold"
)

ggplot2::theme_set(ggplot2::theme_light())

options(
  digits = 3,
  str = strOptions(strict.width = "cut"),
  width = 69,
  tibble.width = 69,
  cli.unicode = FALSE
)
```


# Introduction

```{r, echo=FALSE}
GermanCredit <- read.csv(
  here::here("data/GermanCredit.csv"),
  header = TRUE,
  sep = ";",
  dec = "."
)[,-1]

```


# Exploratory Data Analysis

## Structure & Summary

We are going to start our exploratory data analysis by understanding the data. First, let us observe the type of variables of the dataset:

```{r, echo=FALSE}
str(GermanCredit)
```

We note that all the variables are integer. However, from the data description, a lot of those are actually categorical variables. Hence, in order to have consistent results in our analysis, we are going to transform these variables from integer to factors.
QUESTION: should we keep the head?

```{r, echo=FALSE}
head(GermanCredit)
```

Transformation of integer variables into correct categorical ones, we use a for loop. 
While analysing the data, we noted that the variable "EDUCATION" has one outlier: indeed, in one observation it is equal to "-1" instead of 0/1. For this reason, we change the value of this observation before transforming the variables into categorical ones.

```{r, echo=FALSE}

# changing education
for (i in 1:1000){
  if (GermanCredit[i,8] == "-1") {
    GermanCredit[i,8] <- 1
    GermanCredit[,8] <- as.factor(GermanCredit[,8])
  }
}

for (i in (1:31)) {
  if (is.integer(GermanCredit[,i]) & i != 2 & i !=10  & i != 13  & i !=22  & i !=26  & i != 28) {
  GermanCredit[,i] <- as.factor(GermanCredit[,i])
  }
}

```

```{r, echo=FALSE}
str(GermanCredit) #la structure après les modifs. Je t'ai noté les trucs bizarres que j'ai vu mais n'hésites pas à re-checker au cas où
```

Now that the variables are in the correct form, we can move one with our analysis.

We start by looking at the structure of the dataset.

```{r, echo=FALSE}
library(DataExplorer)
plot_intro(GermanCredit)

types<-inspect_types(GermanCredit)
show_plot(types, col_palette=2)
```

From the first plot, we note that there are no missing observations. Moreover, after the variables transformation 81% of them have discrete values, meaning that these are categorical variables. That is confirmed by the second plot that gives us the exact number of columns which are integer and the ones that are factors (categorical variables).

We are now going to dive deeper into the variables' analysis. 

```{r, echo=FALSE}
library(psych)
library(Hmisc)
summary(GermanCredit)
describe(GermanCredit) # QUESTION: shoul we keep this? I'm not sure it gives us a lot of useful info
```

The summary gives us a first overview of the variables' details. Interestingly, some categorical variables present an unequal distribution of values. For instance, we note that the variable "CO.APPLICANT" is 0 959 times and 1 only 41 times. A similar comment can be made for other categorical variables like "MALE_MAR_or_WID", "FOREIGN", "MALE_DIV", "EDUCATION". This finding is particularly interesting as it raises the following question: is the value of a categorical variable discriminatory for the outcome of the response variable? For instance, if we have an observation where "CO.APPLICANT" = 1, what is the value of "RESPONSE"? QUESTION: Est ce qu'on met ca ou ce n est pas clair?

Let us now analyse the non-categorical variables. For those, we can look at the min and the max, which gives us a range. For instance, we see that in this bank the duration of the loan goes from 4 to 72 months. Moreover, we see that the Max variable "AGE" is 125. This is an inconsistency in the dataset. First, we are going to see if such observation is just one outlier or if there are many of them, and then, we are going to remove them. This will allows us to have robust results.


```{r, echo=FALSE}

GermanCredit %>% 
  select (AGE) %>% 
  group_by(AGE) %>% 
  count() %>% 
  arrange(desc(AGE)) %>% kable()
```

Only one observation has AGE = 125, so we remove it from the dataset.

```{r, echo=FALSE}
GermanCredit <- GermanCredit %>% 
  filter(AGE != "125")
```

```{r, echo=FALSE}
library(DT)
datatable(head(GermanCredit), class = "cell-border stripe") #Ca apparait pas haha 
# PIA: à checker quand on va knit
#QUESTION: finalement ca aussi c'est le head donc on peut le mettre à la place de celui au debut pour ne pas se repeter
```

```{r, echo=FALSE}
library(inspectdf)
# types<-inspect_types(GermanCredit)
# show_plot(types, col_palette=2)

# num.var<-inspect_num(GermanCredit)
# show_plot(num.var, col_palette=3)
#QUESTION: we have the same histogram below, I think we should remove this one so we don't repeat ourselves

cat.var<-inspect_cat(GermanCredit) 
show_plot(cat.var) 

```

This plot allows us to have a better visualization of how the factor variables are distributed. We confim that for most of them, the amount of times their values is 0 is not equal to when they have a value of 1. The only variable that seems to have a similar distribution of 1 and 0 is MALE_SINGLE. 

## Histogram & Density

```{r, echo=FALSE}
library(ggplot2)
#new
num.var<-inspect_num(GermanCredit)
show_plot(num.var, col_palette=3)

#old
plot_histogram(GermanCredit[,-31])
plot_density(GermanCredit[,-31],
             ggtheme = theme_bw())

# GermanCredit %>% 
#   group_by(DURATION) %>% 
#   count() %>% 
#   arrange(desc(DURATION))

#QUESTION: there is one duration of 72 years.. outlier?
```

We are going to comment the histogram for each variable. 
First, let us look at AGE. Most of the people taking the credit are between their 20s and 40s. However, the age range is quite large and it is not uncommon to see people over 60 getting a credit in this dataset. 

Second, we shall analysis AMOUNT. This variable is mostly concentrated between 0 and 5000. It looks like in this dataset in it rare to have a high credits (> 10'000).

Third, we look at the DURATION of the credits. Most of them are going to last between 5 and 20 years. Sometime the duration can last even longer, and we can image that this will be the case for high credits. 

Lastly, we can observe that the most of the time the install rate is at 4%, 60% of the people in the dataset have 1 credit and to conclude, the number of dependents can either be 1 or 2. Even though it assumes only two values, this variable is not going to change into factor because 1 and 2 represent the number of people for whom liable to provide maintenance and a category. 

## Side-by-side boxplots

```{r, echo=FALSE}
plot_boxplot(GermanCredit,
             by = 'RESPONSE',
             ncol = 2,
             title = "Side-by-side boxplots")


```

The boxplot confirm what stated before. For each variable, we see in which range most values stand according the outcome variable RESPONSE. Moreover, it allows us to have a visual representation of possible outliers: for instance, we see that for AMOUNT there is one observation where the credit is really high, and the outcome variable RESPONSE is 0. 
Moreover, we couls sat that for credits between 25 and 40 years, we expect RESPONSE = 0. QUESTION, est ce que c'est correct?


```{r, echo=FALSE}
#QUESTION: same as above, which one do we keep?

lblue <- "#6699CC"
par(mfrow = c(2, 3))

boxplot(AGE ~ RESPONSE, data = GermanCredit, xlab = "Response", notch = T, 
    varwidth = T, col = lblue)
boxplot(AMOUNT ~ RESPONSE, data = GermanCredit, xlab = "Response", varwidth = T, col = lblue)
boxplot(DURATION ~ RESPONSE, data = GermanCredit, xlab = "Response", varwidth = T, col = lblue)
boxplot(INSTALL_RATE ~ RESPONSE, data = GermanCredit, xlab = "Response", varwidth = T, col = lblue)
boxplot(NUM_CREDITS ~ RESPONSE, data = GermanCredit, xlab = "Response", varwidth = T, col = lblue)


```

## Good vs Bad credits
```{r, echo=FALSE}

#CHECK QUE TOUTES LES VARIABLES ON ETE CONSIDERE
GermanCredit %>% 
  select(TELEPHONE, RADIO.TV, RESPONSE) %>% 
  explore_all(target = RESPONSE)

GermanCredit %>% 
  select(NEW_CAR, USED_CAR,FURNITURE,EDUCATION, RESPONSE) %>% 
  explore_all(target = RESPONSE)

GermanCredit %>% 
  select(FOREIGN, MALE_DIV, MALE_SINGLE, MALE_MAR_or_WID, RESPONSE) %>% 
  explore_all(target = RESPONSE)

GermanCredit %>% 
  select(GUARANTOR, CO.APPLICANT, PROP_UNKN_NONE, OTHER_INSTALL, RESPONSE) %>% 
  explore_all(target = RESPONSE)

GermanCredit %>% 
  select(REAL_ESTATE, RENT, OWN_RES, RETRAINING, RESPONSE) %>% 
  explore_all(target = RESPONSE)

```

Similarly to what we saw in the boxplot for the integer variables, now for all the catgorical ones we see how their value is distributed according to the outcome variable RESPONSE.

We note that there are no discrimination for any variable, meaning that we are not going to be able to define RESPONSE only by looking at one variable.

After having deeply analysed the dataset, we are now going to look at the correlation between the variables and then proceed with the model analysis.

## Correlations

```{r, echo=FALSE, fig.width= 8, fig.height= 7}
library(GGally)
plot_correlation(GermanCredit, type= 'c', cor_args = list( 'use' = 'complete.obs'))
```


From the correlation matrix we see taht only duration and amount are correlated. Moreover, they are positively correlated. It seems like there is no correlation between the other variables, whis is actually positive since it means that we won't have problems of multicollinearity. 






