---
title: "Modeling"
author: "Maria Pia El Asmar & Hasini Gunawardena"
date: "10/30/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Partition of Data

To begin the modeling section, we start by partitioning the data set into a training set (750 observations) and testing set (250 observations), selected at random.

```{r, echo=FALSE}

row.order <- sample(c(1:1000)) # first randomize the order of the rows
german.tr <- GermanCredit[row.order[1:750],] # take the first 750 (random) rows of german for the training set
german.te <- GermanCredit[row.order[751:1000],]


```

In order to be consistent, we decided to build all models using the caret package.

# Decision Tree with Caret

The first model that we investigate is the decision tree. The model is built on the training set and then the test set is used to measure the prediction capacity of the model. The data is normalised through the preProcess argument. We used the repeated cross-validation method, in order to achieve better results. Also, we balance the data thanks to "sampling = down", to ensure that the prediction capacity on both classes is balanced. Lastly, we perform a tuning of the complexity parameter (cp), to further improve the model.

```{r, echo=FALSE}
library(caret)
hp_ct <- data.frame(cp = seq(from = 0.03, to = 0, by = -0.003))
ct.caret <- train(
  RESPONSE ~ .,
  data = german.tr,
  method = "rpart",
  preProcess = c("center", "scale"),
  trControl = trainControl(
    method = "repeatedcv",
    number = 10,
    repeats = 10,
    verboseIter = FALSE,
    sampling = "down"
  ),
  tuneGrid = hp_ct
)

```

## Best Complexity parameter 
```{r, echo=FALSE}
print(ct.caret) 
plot(ct.caret)

```

By the information provided above, we can see that the best accuracy on the training set is of 65.9%. This is achieved by using a complexity parameter of 0.006.

  ## Confusion Matrix

We are now going to look on the performance on the test set.

```{r, echo=FALSE}
confusionMatrix(predict.train(ct.caret, newdata = german.te), 
                german.te$RESPONSE)


``` 

As we can see, the overall accuracy on the test set is of 62.8%. However, one can observe that even though the prediction capacity on each class is more balanced than if we had not balanced the data, the sensitivity class (1) is better predicted (70.8%) compared to the specificity class (59.6%). This is confirmed in the confusion matrix as well. To further explain, the "1" class is correctly predicted 106 times out of 127 times. Whereas, the "0" class is correctly predicted 51 times out of 123 times. This means that the model performs well in predicting good credit rating candidates. However, if the aim of the project is to uncover bad credit rating candidates based on the explanatory variables, the model will do a poorer job.

  ## Tree drawing
  
We now plot the final and best model. 
```{r, echo=FALSE}
plot(ct.caret$finalModel)
text(ct.caret$finalModel)

```

# Neural Network with Caret

The second model that we considered is the Neural Network. Similarly to the decision tree, we scaled and balanced the data, as well as, preformed a repeated cross-validation, in order to achieve better results. To go further, we also tuned the "size" and "decay" hyperparameters.

```{r, echo=FALSE, include = FALSE}
set.seed(2006)

hp_nn <- expand.grid(size = 2:4, decay = seq(0, 0.5, 0.05))

credit.nn.caret <- train (
  form = RESPONSE ~ .,
  data = german.tr,
  method = "nnet",
  preProcess = c("center", "scale"),
  trControl = trainControl(
    method = "repeatedcv",
    number = 10,
    repeats = 10,
    verboseIter = FALSE,
    sampling = "down"),
  tuneGrid = hp_nn
)

#final  value 215.167737 
#stopped after 100 iterations

```


## Accuracy measure
  
```{r, echo=FALSE}
print(credit.nn.caret)
plot(credit.nn.caret)
```
  
## Confusion Matrix
```{r, echo=FALSE}
confusionMatrix(predict.train(credit.nn.caret, newdata = german.te), 
                german.te$RESPONSE)
``` 

  ## Neural Network drawing
```{r, echo=FALSE}
library(NeuralNetTools)
plotnet(credit.nn.caret, pos_col = "darkgreen", neg_col = "darkblue")

```

# Logistic regression with caret

```{r, echo=FALSE, warning = FALSE}
set.seed(1)
credit.log.caret <-
  train(
    form = RESPONSE ~ .,
    data = german.tr,
    method = "glm",
    preProcess = c("center", "scale"),
    trControl = trainControl(
      method = "repeatedcv",
      number = 10,
      repeats = 10,
      verboseIter = FALSE,
      sampling = "down"
    )
  )


```


## Accuracy measure
  
```{r, echo=FALSE}
print(credit.log.caret)
summary(credit.log.caret)

```

## Confusion Matrix
```{r, echo=FALSE}
confusionMatrix(predict.train(credit.log.caret, newdata = german.te),
                german.te$RESPONSE)


``` 


# Discriminant Analysis

```{r, echo=FALSE, message= FALSE}
#LDA
# library(MASS)
# lda.fit <- lda(RESPONSE ~ ., data = GermanCredit)
# lda.fit


lda.fit <- caret::train(RESPONSE ~ .,
                         data=german.tr,
                         method="lda",
                         preProcess=c("center", "scale"),
                         trControl=trainControl(method="repeatedcv", number=10,
                         repeats=10, verboseIter=FALSE, sampling = "down")
                         )

lda.fit
```


## Predictions
```{r, echo=FALSE}
lda.pred <- predict(lda.fit, GermanCredit)
names(lda.pred) 

#head(lda.pred$posterior)

```

## Confusion Matrix
```{r, echo=FALSE}
confusionMatrix(predict.train(lda.fit, newdata = german.te),
                german.te$RESPONSE)
```

```{r, echo=FALSE}
# remove
# library(tidyverse)
# library(ggthemes)
# prev.prob.lda$class <- lda.class
# prev.prob.lda$correct <- ifelse(prev.class.lda$actual == prev.class.lda$class, TRUE, 
#     FALSE)
# ggplot(prev.prob.lda, aes(x = class, fill = correct)) + 
#   geom_bar(position = "dodge") + 
#   scale_fill_brewer(palette = "Set1") + 
#   theme_get()
```

# QDA

```{r, echo=FALSE, warning= FALSE}
# qda.fit <- qda(RESPONSE ~ ., data = GermanCredit)
# qda.fit
# 
# #ca me donne une erreure je comprends pas d'oÃ¹ ca viennnnnt
# qda.class <- predict(qda.fit, GermanCredit$RESPONSE)$class 
# table(qda.class, Direction.2005)
set-seed(1)
qda.fit <- caret::train(RESPONSE ~ .,
                         data=german.tr,
                         method="qda",
                         preProcess=c("center", "scale"),
                         trControl=trainControl(method="repeatedcv", number=10,
                         repeats=10, verboseIter=FALSE, sampling = "down")
                         ) 

qda.pred <- predict(qda.fit, GermanCredit)

confusionMatrix(predict.train(qda.fit, newdata = german.te),
                german.te$RESPONSE)

```
    
# KNN

```{r, echo=FALSE}


```

# Support Vector Machine 

```{r, echo=FALSE, warning = FALSE}
library(caret)
model_svm <- caret::train(RESPONSE ~ .,
                          data = german.tr, 
                          method = "svmRadialCost",
                          preProcess = "range",
                          trace = FALSE,
                          trControl = trainControl(method = "repeatedcv", number = 10, repeats = 10, 
                                                  verboseIter = FALSE))
model_svm

# selecting the best tune
model_svm$bestTune
plot(model_svm)


C <- c(0.25, 0.1, 0.5, 1, 10, 100)
sigma <- c(0.0001, 0.001, 0.01, 0.1, 1)
gr.radial<-expand.grid(C = C, sigma = sigma)
model_svm.1<-caret::train(RESPONSE ~ .,
                          data = german.te,
                          method = "svmRadial",
                          preProcess = "range",
                          trace=FALSE,
                          trControl = trainControl(method = "repeatedcv", number = 10, repeats = 10, 
                                                  verboseIter = FALSE),
                          tuneGrid=gr.radial)
model_svm.1
model_svm.1$bestTune
plot(model_svm.1)
model_svm_pred <- predict(model_svm, german.te)
CrossTable(x = german.te$RESPONSE, y = model_svm_pred, prop.chisq = FALSE)

confusionMatrix(predict.train(model_svm, newdata = german.te),
                german.te$RESPONSE)

confusionMatrix(predict.train(model_svm.1, newdata = german.te),
                german.te$RESPONSE)
```

# Ensemble methods (Random Forest)

```{r, echo= FALSE, message = FALSE}
library(randomForest)
library(funModeling)
library(lessR)
library(gmodels)

form <- formula (RESPONSE ~.)

# Call the function:
integ_mod_1 <- data_integrity_model(data = GermanCredit, model_name = "randomForest")
integ_mod_1$data_ok

CreditRF <- randomForest(formula=form, 
                          data=german.tr, 
                          ntree=500, mtry=4, 
                          importance=TRUE, 
                          localImp=TRUE,
                          na.action=na.roughfix,
                          replace=FALSE)

print(CreditRF)

## Variable importance analysis

head(round(importance(CreditRF), 2))

details(varImpPlot(CreditRF))

## Diagnostic model: error rate
round(head(CreditRF$err.rate, 15), 4)

details(plot(CreditRF))

## Confusion matrix

CreditRF$confusion

## Confusion matrix for the test set

CreditRF.pred<-predict(CreditRF, german.te, type="class")
CreditRF.pred

table(true=GermanCredit$RESPONSE[-c(1:750)], pred=CreditRF.pred) #PIA: est ce que c est juste de faire (c(1:750))??

CrossTable(x=GermanCredit$RESPONSE[-c(1:750)], y=CreditRF.pred, prop.chisq=FALSE)

```

## RF with repeated cross-validation

```{r, echo = FALSE, warning=FALSE}
library(caret)
modelLookup(model="rf")

#ca prend beaucouuuup de temps mais a la fin ca marche ahah
  model_rf <- caret::train(RESPONSE ~ .,
                         data=german.tr,
                         method="rf",
                         preProcess=c("center", "scale"),
                         trControl=trainControl(method="repeatedcv", number=10,
                         repeats=10, verboseIter=FALSE, sampling="down")
                         )


model_rf

model_rf$bestTune

# mtry : 

# confusion matrix
confusionMatrix(predict.train(model_rf, newdata = german.te),
                german.te$RESPONSE)

```

## Variable importance analysis

```{r, echo = FALSE}

# ici on devra mettre le alg. BORUTA
varImp(model_rf)
head(round(importance(model_rf), 2))



``` 
## Confusion matrix

```{r, echo = FALSE}
library(gmodels)
model_rf_pred <- predict(model_rf, german.te)
confusionMatrix(model_rf_pred, german.te$RESPONSE)

CrossTable(x=german.te$RESPONSE, y=model_rf_pred, prop.chisq=FALSE)

```





