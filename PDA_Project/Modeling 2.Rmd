---
title: "Modeling"
author: "Maria Pia El Asmar & Hasini Gunawardena"
date: "10/30/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Partition of Data

```{r, echo=FALSE}
library(caret)
# scaling numerical variables
for (i in c(2,10,22)) {
  GermanCredit[,i] <- scale(GermanCredit[,i])
}
    
#--> balance the data: 
# caret: we can specify that we have unbalanced data: down option. It's not necessary to balance directly, we can balance when we use caret.
# sampling = "down"

# ctrl <- trainControl(method = "repeatedcv",
#                      classProbs = TRUE,
#                      ## new option here:
#                      sampling = "down")
# 
# TrainData2 <- train(RESPONSE ~ ., data = GermanCredit,
#                       trControl = ctrl)

```

```{r, echo=FALSE}
library(caret)
set.seed(10666)
val_index <- createDataPartition(GermanCredit$RESPONSE, p = 0.5, list = FALSE)
TrainData <- GermanCredit[val_index, ]
TrainClasses <- GermanCredit[val_index, 31]
head(TrainData)
summary(TrainData)

TestData <- GermanCredit[-val_index, ]
TestClasses <- GermanCredit[-val_index, 31]
head(TestData)
summary(TestData)
```

# Decision Tree
## Model

```{r, echo=FALSE}
library(rpart)
set.seed(123)

credit.ct <- rpart(RESPONSE ~ ., method = "class", data = TrainData, control = rpart.control(minsplit = 4, 
    cp = 1e-05), model = TRUE)

#summary(credit.ct) --> trop long 

par(pty = "s", mar = c(1, 1, 1, 1))
plot(credit.ct, cex = 1)
text(credit.ct, cex = 0.6)

#J'ai pas fait le recursive partitioning up close 

```

## Complexity Table

```{r, echo=FALSE}
printcp(credit.ct)
par(pty = "s")
plotcp(credit.ct)

#Lowest xerror = 0.83333
#1-SE Rule = 0.91781 + 0.055387 = 0.973197 corresponding to cp = 0.0060883  (38 splits) but for visibility purpose let's take the second best --> cp = 0.0159817 (8 splits)
# Il avait dit que size = splits + 1 ---> ce n'est pas le cas ici . random forrest is better.
# cp is too small, 0.01
```

## Tree Number 

```{r, echo = FALSE}
par(pty = "s")
with(credit.ct, plot(cptable[, 3], xlab = "Tree Number", ylab = "Resubstitution Error (R)", 
    type = "b"))

par(pty = "s")
with(credit.ct, plot(cptable[, 4], xlab = "Tree Number", ylab = "Cross-Validated Error (R(cv))", 
    type = "b"))

par(pty = "s")
plotcp(credit.ct)
with(credit.ct, {
    lines(cptable[, 2] + 1, cptable[, 3], type = "b", col = "red")
    legend(2.7, 1, c("Resub. Error", "CV Error", "min(CV Error)+1SE"), lty = c(1, 
        1, 2), col = c("red", "black", "black"), bty = "n", cex = 0.8)
})

##Il faut revoir ça, problème dans légende 

```

## Pruning 

```{r, echo=FALSE}
require(rpart.plot)
credit.prune <- prune(credit.ct, cp = 0.0159817)
summary(credit.prune)
rpart.plot(credit.prune, main = "", extra = 104, under = TRUE, faclen = 0) #On voit quand même rien du tout

```

## Predictions

```{r, echo=FALSE}
library(knitr)
library(caret)
credit.pred <- predict(credit.prune, TestData, type = "class")
kable(table(credit.pred, TestData$RESPONSE), caption = "Prediction table")
#on a de meilleurs résultat en prunant avec 38 splits plutôt que 8 mais on voit rien sur les graphs avec 38 splits.

confusionMatrix(credit.pred,TestData$RESPONSE)
#Accuracy: 0.73


``` 


# Neural Network


```{r, echo=FALSE}
library(nnet)
credit.nn<- nnet(RESPONSE ~ ., data = TrainData, size = 1, rang = 0.1, decay = 5e-04, 
    Hess = T, maxit = 200)
#Faut qu'on regarde pour tuner les hyperparamters

```

## Plot
```{r, echo = FALSE}
library(NeuralNetTools)
library(gmodels)

nnetFit <- caret::train(RESPONSE ~ ., data = TrainData, method = "nnet", preProcess = "range", 
    trace = FALSE, trControl = trainControl(method = "cv"))

nnetFit

confusionMatrix(predict(nnetFit, TestData[, -31]), TestClasses)

german.pred <- predict(nnetFit, TestData[, -31])
CrossTable(x = TestClasses, y = german.pred, prop.chisq = FALSE)
```

# Logistic regression 

```{r, echo=FALSE}
credit.log <- glm(RESPONSE ~ ., data = TrainData, family = binomial)
summary(credit.log)

```

## Finding a Better Model

```{r, echo=FALSE}
step(credit.log)

```
## Better model

```{r, echo=FALSE}
credit.log.better <- glm(formula = RESPONSE ~ CHK_ACCT + DURATION + HISTORY + USED_CAR + 
    FURNITURE + RADIO.TV + RETRAINING + AMOUNT + SAV_ACCT + INSTALL_RATE + 
    GUARANTOR + PROP_UNKN_NONE + AGE + RENT + NUM_CREDITS + TELEPHONE + 
    FOREIGN, family = binomial, data = TrainData)

summary(credit.log.better)

# a lot of variables + some cat variables we have too many levels, so the model has some difficulties to work 
# low std error, it's good. 


```

```{r, echo=FALSE}
coef(credit.log.better)
```

## Predictions
```{r, echo=FALSE}
credit.log.pred <- predict(credit.log.better, type = "response")
kable(table(credit.log.pred, TestData$RESPONSE), caption = "Prediction table")
confusionMatrix(credit.log.pred, TestData$RESPONSE)

##Même problème qu'avant --> je pense que c'est lié au imbalanced data

```


# Discriminant Analysis

```{r, echo=FALSE}


```

# KNN

```{r, echo=FALSE}


```

# Support Vector Machine 

```{r, echo=FALSE}


```

# Ensemble methods (Random Forest)

```{r, echo= FALSE}

library(caret) 
library(randomForest)
library(funModeling)
form <- formula(RESPONSE ~ .)
# Call the function:
integ_mod_1 <- data_integrity_model(data = GermanCredit, model_name = "randomForest") 

integ_mod_1$data_ok
# Any errors ?
integ_mod_1
weatherRF <- randomForest(formula=form,
                          data=GermanCredit, 
                          ntree=500, 
                          mtry=4, 
                          importance=TRUE, 
                          localImp=TRUE, 
                          na.action=na.roughfix, 
                          replace=FALSE)


modelLookup(model="rf") 
system.time(
    model_rf <- caret::train(RESPONSE ~ ., data= TrainData,
                            method="rf",
                            preProcess=NULL, 
                            trControl=trainControl(method="repeatedcv", 
                                                   number=10, repeats=10, 
                                                   verboseIter=FALSE)
                             )
)


model_rf

weather.pred.1 <- predict(model_rf, data[-train, vars.pred]) confusionMatrix(weather.pred.1, data$RainTomorrow[-train]) CrossTable(x=data$RainTomorrow[-train], y=weather.pred.1, prop.chisq=FALSE)
```

